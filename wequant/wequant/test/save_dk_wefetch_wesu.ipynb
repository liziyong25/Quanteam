{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wequant import *\n",
    "from wequant.wefetch import *\n",
    "from wequant.wefetch.query import *\n",
    "from wequant.wefetch.query_ad import *\n",
    "from wequant.wesu import *\n",
    "from wequant.mongo import get_db\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>volunit</th>\n",
       "      <th>decimal_point</th>\n",
       "      <th>name</th>\n",
       "      <th>pre_close</th>\n",
       "      <th>sse</th>\n",
       "      <th>sec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000001</th>\n",
       "      <td>000001</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>平安银行</td>\n",
       "      <td>952.0025</td>\n",
       "      <td>sz</td>\n",
       "      <td>stock_cn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000002</th>\n",
       "      <td>000002</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>万 科Ａ</td>\n",
       "      <td>6.0600</td>\n",
       "      <td>sz</td>\n",
       "      <td>stock_cn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000004</th>\n",
       "      <td>000004</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>*ST国华</td>\n",
       "      <td>648.0400</td>\n",
       "      <td>sz</td>\n",
       "      <td>stock_cn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000006</th>\n",
       "      <td>000006</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>深振业Ａ</td>\n",
       "      <td>648.0000</td>\n",
       "      <td>sz</td>\n",
       "      <td>stock_cn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000007</th>\n",
       "      <td>000007</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>全新好</td>\n",
       "      <td>392.0000</td>\n",
       "      <td>sz</td>\n",
       "      <td>stock_cn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          code  volunit  decimal_point   name  pre_close sse       sec\n",
       "code                                                                  \n",
       "000001  000001      100              2   平安银行   952.0025  sz  stock_cn\n",
       "000002  000002      100              2   万 科Ａ     6.0600  sz  stock_cn\n",
       "000004  000004      100              2  *ST国华   648.0400  sz  stock_cn\n",
       "000006  000006      100              2   深振业Ａ   648.0000  sz  stock_cn\n",
       "000007  000007      100              2    全新好   392.0000  sz  stock_cn"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_list = fetch_stock_list()\n",
    "assert len(stock_list) > 0\n",
    "stock_name_dict = stock_list['name'].to_dict()\n",
    "stock_list.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'datetime_1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymongo import ASCENDING\n",
    "db = get_db()\n",
    "database = db.get_collection('dk_data')\n",
    "database.create_index([('code', ASCENDING)])\n",
    "database.create_index([('datetime', ASCENDING)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00003</th>\n",
       "      <td>00003</td>\n",
       "      <td>00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00005</th>\n",
       "      <td>00005</td>\n",
       "      <td>00005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00020</th>\n",
       "      <td>00020</td>\n",
       "      <td>00020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00027</th>\n",
       "      <td>00027</td>\n",
       "      <td>00027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00029</th>\n",
       "      <td>00029</td>\n",
       "      <td>00029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        code   name\n",
       "code               \n",
       "00003  00003  00003\n",
       "00005  00005  00005\n",
       "00020  00020  00020\n",
       "00027  00027  00027\n",
       "00029  00029  00029"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hkcode_list = fetch_get_hkstock_list('tdx')\n",
    "assert len(hkcode_list) > 0\n",
    "name_code_dict = hkcode_list.set_index('name')['code'].to_dict()\n",
    "hkcode_list.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sucess 【V】奇衡DK全球视野学习材料20251205.xlsx\n",
      "sucess 【V】奇衡DK全球视野学习材料20251204.xlsx\n",
      "sucess 【V】奇衡DK全球视野学习材料20251203.xlsx\n",
      "sucess 【V】奇衡DK全球视野学习材料20251202.xlsx\n",
      "sucess 【V】奇衡DK全球视野学习材料20251201.xlsx\n",
      "sucess 【V】奇衡DK全球视野学习材料20251128.xlsx\n",
      "sucess 【V】奇衡DK全球视野学习材料20251127.xlsx\n",
      "sucess 【V】奇衡DK全球视野学习材料20251126.xlsx\n",
      "sucess 【V】奇衡DK全球视野学习材料20251125.xlsx\n",
      "sucess 【V】奇衡DK全球视野学习材料20251124.xlsx\n",
      "sucess 【V】奇衡DK全球视野学习材料20251121.xlsx\n",
      "sucess 【V】奇衡DK全球视野学习材料20251120.xlsx\n",
      "sucess 【V】奇衡DK全球视野学习材料20251119.xlsx\n",
      "sucess 【V】奇衡DK全球视野学习材料20251118.xlsx\n",
      "sucess 【V】奇衡DK全球视野学习材料20251117.xlsx\n",
      "sucess 【V】奇衡DK全球视野学习材料20251114.xlsx\n",
      "sucess 【V】奇衡DK全球视野学习材料20251113.xlsx\n",
      "sucess 【V】奇衡DK全球视野学习材料20251112.xlsx\n",
      "sucess 【V】奇衡DK全球视野学习材料20251111.xlsx\n",
      "sucess 【V】奇衡DK全球视野学习材料20251111-1.xlsx\n"
     ]
    }
   ],
   "source": [
    "root_path = r\"C:\\Users\\Administrator\\Downloads\\DK\"\n",
    "file_names = os.listdir(root_path)\n",
    "file_names = np.array(file_names)\n",
    "file_names = file_names[[ True if 'V】奇衡DK全球视野学习材料' in file_names[i] else False for i in range(len(file_names))]][::-1]\n",
    "for file_name in file_names[:20]:\n",
    "    s_dk_data = pd.read_excel(r\"%s\\%s\"%(root_path,file_name),sheet_name=None)\n",
    "    sheet_names = np.array(list(s_dk_data.keys()))\n",
    "    total_dk_data = []\n",
    "    for sheet_name in sheet_names:\n",
    "        dk_data = s_dk_data[sheet_name]\n",
    "        dk_data.columns = ['code','name','date','R_value','L_value']\n",
    "        if dk_data['code'].dtype == 'int64':\n",
    "            dk_data['code'] = dk_data['code'].apply(lambda x : \"0\"*(5-len(str(x))) +  str(x))\n",
    "        dk_data = dk_data[['code','R_value','L_value']]\n",
    "        total_dk_data.append(dk_data)\n",
    "    total_dk_data = pd.concat(total_dk_data)\n",
    "    total_dk_data['datetime'] = str(pd.to_datetime(file_name.split(\".\")[0].split(\"-\")[0][-8:]))[:10]\n",
    "    insert_data_json = [i.to_dict() for _,i in total_dk_data.iterrows()]\n",
    "    save_dk_data(pd.DataFrame(insert_data_json))\n",
    "    print(\"sucess\",file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch stock adjustment factors (subset to keep runtime reasonable)\n",
    "codes = list(stock_list.index[:200])\n",
    "data_fq = fetch_stock_adj(codes, '2023-01-01', '2025-01-01', format='pd')\n",
    "assert data_fq is not None and len(data_fq) > 0\n",
    "data_fq.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dk_data = pd.read_excel(r\"%s\\%s\"%(root_path,file_name),sheet_name=sheet_name1)\n",
    "dk_data.columns = dk_data.iloc[0]\n",
    "dk_data=dk_data.iloc[1:]\n",
    "dk_data['code'] = dk_data['NO.'].apply(lambda x : \"0\"*(6-len(str(x))) +  str(x))\n",
    "dk_data=dk_data.iloc[:,2:]\n",
    "dk_columns = ['L_value','R_value','R_switch','L_switch','L_label','R_label','R_bias','L_bias','acitve1','acitve2','exceed1','exceed2','exceed3','switch1','switch2','switch3','code']\n",
    "dk_data.columns = dk_columns\n",
    "dk_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dk_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = r\"C:\\Users\\Administrator\\Downloads\\DK\"\n",
    "file_names = os.listdir(root_path)\n",
    "file_names = np.array(file_names)\n",
    "file_names = file_names[[ True if 'V】奇衡DK星球学习材料' in file_names[i] else False for i in range(len(file_names))]]\n",
    "for file_name in file_names[-5:]:\n",
    "    try:\n",
    "        print(file_name)\n",
    "        date_time = file_name.split(\".\")[0][-1:]\n",
    "        total_dk_data = []\n",
    "        dk_data = pd.read_excel(r\"%s\\%s\"%(root_path,file_name),sheet_name=None)\n",
    "        sheet_names = np.array(list(dk_data.keys()))\n",
    "        print(sheet_names)\n",
    "        sheet_name1 = sheet_names[[True if '矩形' in x else False  for x in sheet_names]][0]\n",
    "        sheet_name2 = sheet_names[[True if 'UBW' in x else False  for x in sheet_names]][0]\n",
    "        sheet_name3 = sheet_names[[True if '原共享' in x else False  for x in sheet_names]][0]\n",
    "        sheet_name4 = sheet_names[[True if '主连' in x else False  for x in sheet_names]][0]\n",
    "        dk_data = pd.read_excel(r\"%s\\%s\"%(root_path,file_name),sheet_name=sheet_name1)\n",
    "        dk_data.columns = dk_data.iloc[0]\n",
    "        dk_data=dk_data.iloc[1:]\n",
    "        dk_data['code'] = dk_data['NO.'].apply(lambda x : \"0\"*(6-len(str(x))) +  str(x))\n",
    "        dk_data=dk_data.iloc[:,2:]\n",
    "        dk_columns = ['L_value','R_value','R_switch','L_switch','L_label','R_label','R_bias','L_bias','acitve1','acitve2','exceed1','exceed2','exceed3','switch1','switch2','switch3','code']\n",
    "        dk_data.columns = dk_columns\n",
    "        total_dk_data.append(dk_data)\n",
    "\n",
    "        dk_data = pd.read_excel(r\"%s\\%s\"%(root_path,file_name),sheet_name=sheet_name2)\n",
    "        dk_data.columns = dk_data.iloc[0]\n",
    "        dk_data=dk_data.iloc[1:]\n",
    "        dk_data['code'] = dk_data['NO.'].apply(lambda x : \"0\"*(6-len(str(x))) +  str(x))\n",
    "        dk_data=dk_data.iloc[:,2:]\n",
    "        dk_columns = ['L_value','R_value','R_switch','L_switch','L_label','R_label','R_bias','L_bias','acitve1','acitve2','exceed1','exceed2','exceed3','switch1','switch2','switch3','code']\n",
    "        dk_data.columns = dk_columns\n",
    "        total_dk_data.append(dk_data)\n",
    "\n",
    "        dk_data = pd.read_excel(r\"%s\\%s\"%(root_path,file_name),sheet_name=sheet_name3)\n",
    "        dk_data.columns = dk_data.iloc[0]\n",
    "        dk_data=dk_data.iloc[1:]\n",
    "        dk_data['code'] = dk_data['NO.'].apply(lambda x : \"0\"*(6-len(str(x))) +  str(x))\n",
    "        dk_data=dk_data.iloc[:,2:]\n",
    "        dk_columns = ['L_value','R_value','R_switch','L_switch','L_label','R_label','R_bias','L_bias','acitve1','acitve2','exceed1','exceed2','exceed3','switch1','switch2','switch3','code']\n",
    "        dk_data.columns = dk_columns\n",
    "        total_dk_data.append(dk_data)\n",
    "\n",
    "\n",
    "        sheet_name5 = sheet_names[[True if '情绪数据库' in x else False  for x in sheet_names]][0]\n",
    "        dk_data = pd.read_excel(r\"%s\\%s\"%(root_path,file_name),sheet_name=sheet_name5)\n",
    "        dk_data = dk_data.iloc[5:,[0,2,3]]\n",
    "        dk_data.columns = ['code','L_value','R_value']\n",
    "        dk_data['code'] = dk_data['code'].apply(lambda x : \"0\"*(6-len(str(x))) +  str(x))\n",
    "        total_dk_data.append(dk_data)\n",
    "\n",
    "        # sheet_name6 = sheet_names[[True if '2023' in x else False  for x in sheet_names]][0]\n",
    "        # dk_data = pd.read_excel(r\"%s\\%s\"%(root_path,file_name),sheet_name=sheet_name6)\n",
    "        # dk_data = dk_data.iloc[5:,[0,2,3]]\n",
    "        # dk_data.columns = ['code','L_value','R_value']\n",
    "        # dk_data['code'] = dk_data['code'].apply(lambda x : \"0\"*(6-len(str(x))) +  str(x))\n",
    "        # total_dk_data.append(dk_data)\n",
    "\n",
    "        dk_data = pd.read_excel(r\"%s\\%s\"%(root_path,file_name),sheet_name=sheet_name4)\n",
    "        dk_data.columns = dk_data.iloc[0]\n",
    "        dk_data=dk_data.iloc[1:]\n",
    "        dk_data['code']=dk_data.iloc[:,0].apply(lambda x : str(x)[:-2])\n",
    "        dk_data=dk_data.iloc[:,2:]\n",
    "        dk_columns = ['L_value','R_value','R_switch','L_switch','L_label','R_label','R_bias','L_bias','acitve1','acitve2','exceed1','exceed2','exceed3','switch1','switch2','switch3','code']\n",
    "        dk_data.columns = dk_columns\n",
    "        total_dk_data.append(dk_data)\n",
    "        total_dk_data = pd.concat(total_dk_data)\n",
    "        total_dk_data['datetime'] = file_name.split(\".\")[0][-8:]\n",
    "        total_dk_data = total_dk_data.fillna(0)\n",
    "\n",
    "        if '指数数据库' in sheet_names:\n",
    "            sheet_name5 = sheet_names[[True if '指数数据库' in x else False  for x in sheet_names]][0]\n",
    "            dk_data = pd.read_excel(r\"%s\\%s\"%(root_path,file_name),sheet_name=sheet_name5)\n",
    "            dk_data.columns = dk_data.iloc[0]\n",
    "            dk_data=dk_data.iloc[1:]\n",
    "            dk_data['code'] = dk_data['NO.'].apply(lambda x : \"9\" + \"0\"*(6-len(str(x))) +  str(x))\n",
    "            dk_data=dk_data.iloc[:,2:]\n",
    "            dk_columns = ['L_value','R_value','R_switch','L_switch','L_label','R_label','R_bias','L_bias','acitve1','acitve2','exceed1','exceed2','exceed3','switch1','switch2','switch3','code']\n",
    "            dk_data.columns = dk_columns\n",
    "            total_dk_data.append(dk_data)\n",
    "\n",
    "        total_dk_data = total_dk_data.drop_duplicates(\"code\")\n",
    "        date_time = str(pd.to_datetime(file_name.split(\".\")[0][-8:]))[:10]\n",
    "        fq_dict = data_fq[data_fq['date']==date_time].set_index(\"code\")['adj'].to_dict()\n",
    "        total_dk_data['adj'] = total_dk_data['code'].apply(lambda x : fq_dict[x] if x in fq_dict.keys() else 1)\n",
    "        total_dk_data['L_value_adj'] = total_dk_data.apply(lambda x : x['adj']*x['L_value'],axis=1)\n",
    "        total_dk_data['R_value_adj'] = total_dk_data.apply(lambda x : x['adj']*x['R_value'],axis=1)\n",
    "        insert_data_json = [i.to_dict() for _,i in total_dk_data.iterrows()]\n",
    "        save_dk_data(pd.DataFrame(insert_data_json))\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dk_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futute_list = fetch_future_list()\n",
    "future_market_code = {30: 'SHFE', 29: 'DCE', 28: 'CZCE', 47: 'CFFEX'}\n",
    "futute_list = futute_list.loc[list(futute_list[futute_list['name'].apply(lambda x: '??' in x)].index)]\n",
    "futute_list['TB_code'] = futute_list['code'].apply(lambda x: x[:-2])\n",
    "futute_list['market'] = futute_list['market'].apply(lambda x: future_market_code.get(x, x))\n",
    "future_exchange = futute_list.set_index('TB_code')['market'].to_dict()\n",
    "\n",
    "# Build DK codes (A-shares use .SZ/.SH, ETF use 6-digit code) and fetch DK data\n",
    "etf_list = fetch_etf_list()\n",
    "stock_dk_codes = stock_list.apply(lambda r: f\"{r['code']}.{str(r['sse']).upper()}\", axis=1).tolist()\n",
    "etf_codes = list(etf_list.index)\n",
    "# Also include futures already present in dk_data (ensures non-empty future slice)\n",
    "db = get_db()\n",
    "future_codes = db['dk_data'].distinct('code', {'type': 'future'})\n",
    "code_list = stock_dk_codes[:500] + etf_codes[:200] + list(future_codes)\n",
    "\n",
    "min_dt = db['dk_data'].find_one({}, sort=[('datetime', 1)], projection={'datetime': 1})['datetime']\n",
    "max_dt = db['dk_data'].find_one({}, sort=[('datetime', -1)], projection={'datetime': 1})['datetime']\n",
    "start = pd.to_datetime(min_dt).strftime('%Y-%m-%d')\n",
    "end = pd.to_datetime(max_dt).strftime('%Y-%m-%d')\n",
    "dk_data = fetch_dk_data(code_list, start, end, format='pd').sort_values(['code', 'datetime'])\n",
    "assert dk_data is not None and len(dk_data) > 0\n",
    "max_date = dk_data['date'].max()\n",
    "R_symbols = list(dk_data.query('date==@max_date and R_label==1')['code'])\n",
    "date = max_date\n",
    "dk_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dk_data: A-share codes use .SZ/.SH, ETF codes use 6-digit code\n",
    "_stock_list = stock_list.apply(lambda r: f\"{r['code']}.{str(r['sse']).upper()}\", axis=1).tolist()\n",
    "_etf_list = list(fetch_etf_list().index)\n",
    "len(_stock_list), len(_etf_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = file_names[-1]\n",
    "qx_data = pd.DataFrame(pd.read_excel(r\"%s\\%s\"%(root_path,file_name),sheet_name='情绪数据库').iloc[5:,[0,-1]])\n",
    "qx_data.columns = ['code','date']\n",
    "qx_data['code'] = qx_data['code'].astype(\"str\")\n",
    "qx_data['code'] = qx_data.apply(lambda x : \"0\"*(6-len(str(x['code'])))+str(x['code']),axis=1)\n",
    "qx_data_dict = qx_data.groupby(\"code\").count()['date'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_dk_data = dk_data.query(\"code in @_stock_list\").sort_values(\"R_value\").drop_duplicates([\"code\",'datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dk_Rtrend_dict = (stock_dk_data.pivot_table('R_value',index='datetime',columns='code').pct_change().iloc[-1]*100).to_dict()\n",
    "dk_Ltrend_dict = (stock_dk_data.pivot_table('L_value',index='datetime',columns='code').pct_change().iloc[-1]*100).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a subset to keep memory/time reasonable\n",
    "data_obj = fetch_stock_day_adv(_stock_list[:300], '2024-01-01', '2026-01-01')\n",
    "assert data_obj is not None\n",
    "stock_data = data_obj.to_qfq().data\n",
    "assert stock_data is not None and len(stock_data) > 0\n",
    "stock_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vectorbt as vbt\n",
    "open_price = np.array(stock_data.pivot_table(\"open\",columns='code',index='date').ffill())\n",
    "ffill_high = np.array(stock_data.pivot_table(\"high\",columns='code',index='date').ffill())\n",
    "ffill_low = np.array(stock_data.pivot_table(\"low\",columns='code',index='date').ffill())\n",
    "ffill_close = np.array(stock_data.pivot_table(\"close\",columns='code',index='date').ffill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorbt.generic.nb import *\n",
    "from vectorbt.base.reshape_fns import to_2d_array,to_1d_array\n",
    "from vectorbt.indicators.nb import true_range_nb,macd_apply_nb,ma_nb,stoch_apply_nb,stoch_cache_nb\n",
    "@njit\n",
    "def calc_macd(close,fast_window=6,slow_window=13,signal_window=5,emw=True,adjust=False):\n",
    "    fast_ma = ma_nb(close,window=fast_window,ewm=True,adjust=adjust)\n",
    "    slow_ma = ma_nb(close,window=slow_window,ewm=True,adjust=adjust)\n",
    "    macd_diff = fast_ma - slow_ma\n",
    "    macd_dea = ma_nb(macd_diff, window = signal_window, ewm = True, adjust=adjust)\n",
    "    macd_value = 2*(macd_diff-macd_dea)\n",
    "    return macd_value,macd_diff,macd_dea\n",
    "@njit\n",
    "def calc_kdj(high: tp.Array2d, low: tp.Array2d, close: tp.Array2d,\n",
    "                   k_window: int, d_window: int, d_ewm: bool, adjust: bool):\n",
    "    roll_min = rolling_min_nb(low,k_window)\n",
    "    roll_max = rolling_max_nb(high,k_window)\n",
    "    rsv = 100 * (close - roll_min) / (roll_max - roll_min)\n",
    "    percent_k = ma_nb(rsv, d_window, d_ewm, adjust=adjust)\n",
    "    percent_d = ma_nb(percent_k, d_window, d_ewm, adjust=adjust)\n",
    "    percent_j = 3*percent_k-2*percent_d\n",
    "    return percent_k, percent_d,percent_j\n",
    "@njit\n",
    "def rolling_sort_nb(a,window=20):\n",
    "    out = np.full_like(a,np.nan,dtype=np.float_)\n",
    "    for col in range(a.shape[1]):\n",
    "        rank_value = np.argsort(a[:window+1,col][-window:])[-1]\n",
    "        for i in range(window,a.shape[0]):\n",
    "            out[i, col] = rank_value\n",
    "            if a[i,col]>a[i-window,col]:\n",
    "                rank_value = min(rank_value+1,window)\n",
    "            else:\n",
    "                rank_value = max(rank_value-1,0)\n",
    "    return out/window\n",
    "@njit\n",
    "def calc_WR(high,low,close,window=10):\n",
    "    wr = (rolling_max_nb(high,window)-close) / (rolling_max_nb(high,window)-rolling_min_nb(low,window))*100\n",
    "    return wr\n",
    "percent_k, percent_d,percent_j= calc_kdj(ffill_high,ffill_low,ffill_close,k_window = 9,d_window=3,d_ewm=False,adjust= False)\n",
    "wr = calc_WR(ffill_high,ffill_low,ffill_close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = stock_data.pivot_table(\"close\",columns='code',index='date')\n",
    "kdj_dict = close.vbt.wrapper.wrap(percent_j).iloc[-1].to_dict()\n",
    "wr_dict = close.vbt.wrapper.wrap(wr).iloc[-1].to_dict()\n",
    "ma250_dict = close.rolling(250).mean().iloc[-1].to_dict()\n",
    "ma20_dict = close.rolling(20).mean().iloc[-1].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from WindPy import *\n",
    "# w.start()\n",
    "# _wind_stock_list = [i+\".SH\" if i[0] == \"6\" else i+\".SZ\" for i in _stock_list]\n",
    "# wind_data = w.wss(_wind_stock_list, \"briefing\")\n",
    "# wind_ind_data = pd.DataFrame(wind_data.Data[0],index=wind_data.Codes)\n",
    "# wind_ind_data.to_excel(\"wind.xlsx\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = str(max_date)[:10]\n",
    "# s_dk_data = dk_data.drop_duplicates(\"code\",keep='last')\n",
    "# s_dk_data = s_dk_data[(s_dk_data['code'].isin(_stock_list)) ]\n",
    "# s_dk_data['thscode'] = s_dk_data['code'].apply(lambda x : x+\".SZ\" if x[0] in [\"0\",\"1\",\"3\"] else str(x)+\".SH\")\n",
    "# symbols = list(s_dk_data[s_dk_data['code'].apply(lambda x : x[:1] in ['0','3','6'])]['thscode'])\n",
    "# ths_data = pd.concat(\n",
    "# [\n",
    "#         THS_BD(symbols[:500],'ths_the_ths_industry_stock;ths_main_businuess_stock','100,%s;%s'%(d,d)).data.set_index(\"thscode\"),\n",
    "#         THS_BD(symbols[500:1000],'ths_the_ths_industry_stock;ths_main_businuess_stock','100,%s;%s'%(d,d)).data.set_index(\"thscode\"),\n",
    "#         THS_BD(symbols[1000:1500],'ths_the_ths_industry_stock;ths_main_businuess_stock','100,%s;%s'%(d,d)).data.set_index(\"thscode\"),\n",
    "#         THS_BD(symbols[1500:2000],'ths_the_ths_industry_stock;ths_main_businuess_stock','100,%s;%s'%(d,d)).data.set_index(\"thscode\"),\n",
    "#         THS_BD(symbols[2000:2500],'ths_the_ths_industry_stock;ths_main_businuess_stock','100,%s;%s'%(d,d)).data.set_index(\"thscode\"),\n",
    "#         THS_BD(symbols[2500:3000],'ths_the_ths_industry_stock;ths_main_businuess_stock','100,%s;%s'%(d,d)).data.set_index(\"thscode\"),\n",
    "#         THS_BD(symbols[3000:3500],'ths_the_ths_industry_stock;ths_main_businuess_stock','100,%s;%s'%(d,d)).data.set_index(\"thscode\"),\n",
    "#         THS_BD(symbols[3500:4000],'ths_the_ths_industry_stock;ths_main_businuess_stock','100,%s;%s'%(d,d)).data.set_index(\"thscode\"),\n",
    "#         THS_BD(symbols[4000:4500],'ths_the_ths_industry_stock;ths_main_businuess_stock','100,%s;%s'%(d,d)).data.set_index(\"thscode\"),\n",
    "#         THS_BD(symbols[4500:5000],'ths_the_ths_industry_stock;ths_main_businuess_stock','100,%s;%s'%(d,d)).data.set_index(\"thscode\"),\n",
    "#         THS_BD(symbols[5000:5500],'ths_the_ths_industry_stock;ths_main_businuess_stock','100,%s;%s'%(d,d)).data.set_index(\"thscode\"),\n",
    "#         THS_BD(symbols[5500:6000],'ths_the_ths_industry_stock;ths_main_businuess_stock','100,%s;%s'%(d,d)).data.set_index(\"thscode\"),\n",
    "#         THS_BD(symbols[6500:],'ths_the_ths_industry_stock;ths_main_businuess_stock','100,%s;%s'%(d,d)).data.set_index(\"thscode\"),\n",
    "# ]\n",
    "# )\n",
    "# ths_data.to_excel(\"ths1.xlsx\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ths_data = pd.read_excel(\"ths.xlsx\").set_index('Unnamed: 0')\n",
    "ths_data['code']=ths_data.index\n",
    "ths_data['code']=ths_data['code'].apply(lambda x : x[:6])\n",
    "ths_data = ths_data.query(\"code !='100'\")\n",
    "def tb_symbol(x):\n",
    "    if x[:2] in ['60','50','51','56','58','68']:\n",
    "        x = x +\".SSE\"\n",
    "    elif x[:2] in ['00','30','15']:\n",
    "        x = x +\".SZSE\"\n",
    "    else :\n",
    "        x = x+\"888\"+future_exchange[x] if len(x)==2 else x+\"9888\" +\".\"+future_exchange[x]\n",
    "    return x \n",
    "#ths_data[0]=ths_data[0].apply(lambda x : str(x).replace(\"。\",\"\\n\") )\n",
    "ths_data['TB_code'] = ths_data['code'].apply(lambda x :tb_symbol(x))\n",
    "ths_data.to_csv(\"D:/ths.csv\",index=True,encoding='gb18030')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"ths.xlsx\").set_index('Unnamed: 0')\n",
    "work_dict = data[0].to_dict()\n",
    "data = pd.read_excel(\"ths1.xlsx\").set_index('thscode')\n",
    "industry_dict = data['ths_the_ths_industry_stock'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_high = stock_data.pivot_table(\"close\",index='date',columns='code')\n",
    "R_value = dk_data.pivot_table(\"R_value\",index='date',columns='code').loc[:,stock_high.columns]\n",
    "stock_high = stock_data.pivot_table(\"close\",index='date',columns='code').loc[R_value.index]\n",
    "raw_R_value = R_value.loc[stock_high.index]\n",
    "R_value = R_value.loc[stock_high.index].ffill()\n",
    "R_bias = stock_high-R_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_value.columns[(np.sum(R_bias.iloc[-20:]>0)>10) & (R_bias>0).iloc[-1] & (R_bias<0.05).iloc[-1] &(np.isnan(raw_R_value.iloc[-20:]).sum() < 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwings as xw\n",
    "app = xw.App(visible=True, add_book=True)\n",
    "app.display_alerts = True  # 关闭一些提示信息，可以加快运行速度。 默认为 True。\n",
    "app.screen_updating = True  # 更新显示工作表的内容。默认为 True。关闭它也可以提升运行速度。\n",
    "app.interactive = True\n",
    "wb = app.books.open(\"D:/复盘.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sht = wb.sheets['科创生物']\n",
    "# for i in range(2,50):\n",
    "#     _symbol = sht.range(\"A%s\"%i).value\n",
    "#     if _symbol in s_dk_data.index:\n",
    "#         s_df = s_dk_data.loc[_symbol]\n",
    "#         sht.range(\"C%s\"%i).value = s_df['L_value']\n",
    "#         sht.range(\"D%s\"%i).value = s_df['R_value']\n",
    "#         sht.range(\"K%s\"%i).value = list(s_df[['acitve1', 'acitve2', 'exceed1', 'exceed2',\n",
    "#             'exceed3', 'switch1', 'switch2', 'switch3']])\n",
    "#         sht.range(\"AA%s\"%i).value = str(s_df['date'])[:10]\n",
    "#         #sht.range(\"K%s\"%i).value = s_df['acitve1']\n",
    "#         # sht.range(\"L%s\"%i).value = s_df['acitve2']\n",
    "#         # sht.range(\"M%s\"%i).value = s_df['exceed1']\n",
    "#         # sht.range(\"N%s\"%i).value = s_df['exceed2']\n",
    "#         # sht.range(\"O%s\"%i).value = s_df['exceed3']\n",
    "#         # sht.range(\"P%s\"%i).value = s_df['switch1']\n",
    "#         # sht.range(\"Q%s\"%i).value = s_df['switch2']\n",
    "#         sht.range(\"U%s\"%i).value = ma250_dict[_symbol[:6]]\n",
    "#         sht.range(\"V%s\"%i).value = kdj_dict[_symbol[:6]]\n",
    "#         sht.range(\"X%s\"%i).value = wr_dict[_symbol[:6]]\n",
    "#         sht.range(\"Y%s\"%i).value = dk_Rtrend_dict[_symbol[:6]]\n",
    "#         sht.range(\"Z%s\"%i).value = dk_Ltrend_dict[_symbol[:6]]\n",
    "#         if _symbol[:6] in qx_data_dict.keys():\n",
    "#             sht.range(\"W%s\"%i).value = qx_data_dict[_symbol[:6]]\n",
    "#     sht.range(\"AB%s\"%i).value = work_dict[_symbol]\n",
    "#     sht.range(\"J%s\"%i).value = industry_dict[_symbol]\n",
    "#     sht.range(\"I%s\"%i).value = stock_name_dict[_symbol[:6]]\n",
    "#     sht.range(\"I%s\"%i).value = stock_name_dict[_symbol[:6]]\n",
    "#     #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list = fetch_stock_list()\n",
    "stock_name_dict = stock_list['name'].to_dict()\n",
    "sht = wb.sheets['股票']\n",
    "sht_codes = sht.range(\"A2\").expand(\"down\").value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sht = wb.sheets['股票']\n",
    "s_dk_data = dk_data.drop_duplicates(\"code\",keep='last')\n",
    "s_dk_data['thscode'] = s_dk_data['code'].apply(lambda x : x+\".SZ\" if x[0] in [\"0\",\"1\",\"3\"] else str(x)+\".SH\")\n",
    "s_dk_data['work'] = s_dk_data['thscode'].apply(lambda x : work_dict[x] if x in work_dict.keys() else None)\n",
    "s_dk_data['industry'] = s_dk_data['thscode'].apply(lambda x : industry_dict[x] if x in work_dict.keys() else None)\n",
    "s_dk_data['short_name'] = s_dk_data['code'].apply(lambda x : stock_name_dict[x] if x in stock_name_dict.keys() else None)\n",
    "s_dk_data = s_dk_data.set_index(\"thscode\")\n",
    "sht_df = s_dk_data.loc[sht_codes]\n",
    "sht_df['MA250'] = sht_df['code'].apply(lambda x : ma250_dict[x])\n",
    "sht_df['KDJ'] = sht_df['code'].apply(lambda x : kdj_dict[x])\n",
    "sht_df['QX'] = sht_df['code'].apply(lambda x : qx_data_dict[x] if x in qx_data_dict.keys() else 0)\n",
    "sht_df['WR'] = sht_df['code'].apply(lambda x : wr_dict[x])\n",
    "sht_df['TR'] = sht_df['code'].apply(lambda x : dk_Rtrend_dict[x])\n",
    "sht_df['RL'] = sht_df['code'].apply(lambda x : dk_Ltrend_dict[x])\n",
    "sht.range(\"C2\").value = sht_df[['L_value','R_value']].values\n",
    "sht.range(\"I2\").value = sht_df[['short_name','industry']].values\n",
    "sht.range(\"K2\").value = sht_df[['acitve1', 'acitve2', 'exceed1', 'exceed2',\n",
    "    'exceed3', 'switch1', 'switch2', 'switch3']].values\n",
    "sht.range(\"U2\").value = sht_df[['MA250', 'KDJ', 'QX', 'WR',\n",
    "    'TR', 'RL','date','work']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sht= wb.sheets['ETF']\n",
    "cols = ['pct_change','L_value', 'R_value','price','R_bias','L_bias','acitve1', 'acitve2', 'exceed1', 'exceed2',\n",
    "       'exceed3', 'switch1', 'switch2', 'switch3','short_name']\n",
    "s_dk_data['R_bias']  = None\n",
    "s_dk_data['L_bias']  = None  \n",
    "s_dk_data['price']  = None\n",
    "s_dk_data['pct_change']  = None\n",
    "sht.range('A1').value = s_dk_data.query(\"code in @_etf_list\")[cols]\n",
    "\n",
    "sht.range(\"B2\").value = '=RTD(\"tdf.quote\",\"\",A2,\"changeRatio\")' \n",
    "sht.range(\"E2\").value = '=RTD(\"tdf.quote\",\"\",A2,\"new\")' \n",
    "sht.range(\"F2\").value = '=(E2/D2-1)*100'\n",
    "sht.range(\"G2\").value = '=(E2/C2-1)*100'\n",
    "sht.range(\"H2\").value = '=(E2/S2-1)*100'\n",
    "xw.Range('A1:W1').color = (230, 0, 0)  # or '#ffffff'\n",
    "xw.Range('A1:W1').font.bold = True\n",
    "xw.Range('A1:W1').row_height = 40\n",
    "xw.Range('A1:W1').column_width = 7\n",
    "xw.Range('A1:W1').api.WrapText = True\n",
    "sht.range('B:H').number_format = '0.00'\n",
    "sht.range('Q:T').number_format = '0.00'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_dk_data = dk_data[ (dk_data['date']==max_date) & (dk_data['code'].isin(_etf_list)) ]\n",
    "s_dk_data['thscode'] = s_dk_data['code'].apply(lambda x : x+\".SZ\" if x[0] in [\"0\",\"1\",\"3\"] else str(x)+\".SH\")\n",
    "symbols = list(s_dk_data['thscode'])\n",
    "sht = wb.sheets['ETF']\n",
    "for i in range(2,1000):\n",
    "    _symbol = sht.range(\"A%s\"%i).value\n",
    "    if _symbol in s_dk_data.index:\n",
    "        s_df = s_dk_data.loc[_symbol]\n",
    "        sht.range(\"C%s\"%i).value = s_df['L_value']\n",
    "        sht.range(\"D%s\"%i).value = s_df['R_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# migrated: use wequant.wefetch.fetch_dk_data instead of local QA_fetch_hkdk_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_dk_data = fetch_dk_data(list(hkcode_list['code']), '2016-01-01', '2026-01-01', format='pd')\n",
    "assert s_dk_data is not None and len(s_dk_data) > 0\n",
    "s_dk_data = s_dk_data.drop_duplicates(subset=['code'], keep='last')\n",
    "symbols = list(s_dk_data['code'])\n",
    "symbols = [i[1:] + '.HK' for i in symbols]\n",
    "s_dk_data['thscode'] = s_dk_data['code'].apply(lambda x: x[1:] + '.HK')\n",
    "sht = wb.sheets['??']\n",
    "s_dk_data = s_dk_data.set_index('code')\n",
    "for i in range(2, 200):\n",
    "    _symbol = '0' + str(sht.range(f'A{i}').value).split('.')[0]\n",
    "    if _symbol in s_dk_data.index:\n",
    "        s_df = s_dk_data.loc[_symbol]\n",
    "        sht.range(f'C{i}').value = s_df['L_value']\n",
    "        sht.range(f'D{i}').value = s_df['R_value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed: stray break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwings as xw\n",
    "app = xw.App(visible=True, add_book=True)\n",
    "app.display_alerts = True  # 关闭一些提示信息，可以加快运行速度。 默认为 True。\n",
    "app.screen_updating = True  # 更新显示工作表的内容。默认为 True。关闭它也可以提升运行速度。\n",
    "app.interactive = True\n",
    "wb = app.books.add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sht= wb.sheets.add(\"股票\")\n",
    "s_dk_data = dk_data.drop_duplicates(\"code\",keep='last')\n",
    "s_dk_data['thscode'] = s_dk_data['code'].apply(lambda x : x+\".SZ\" if x[0] in [\"0\",\"1\",\"3\"] else str(x)+\".SH\")\n",
    "s_dk_data['work'] = s_dk_data['thscode'].apply(lambda x : work_dict[x] if x in work_dict.keys() else None)\n",
    "s_dk_data['thscode'] = s_dk_data['code'].apply(lambda x : x+\".SZ\" if x[0] in [\"0\",\"1\",\"3\"] else str(x)+\".SH\")\n",
    "cols = ['pct_change','L_value', 'R_value','price','R_bias','L_bias','MA250_bias','short_name','industry','acitve1', 'acitve2', 'exceed1', 'exceed2',\n",
    "       'exceed3', 'switch1', 'switch2', 'switch3','PE','MV','MA250', 'KDJ','QX','work',\n",
    "       ]\n",
    "s_dk_data['R_bias']  = None\n",
    "s_dk_data['L_bias']  = None  \n",
    "s_dk_data['MA250_bias']  = None\n",
    "s_dk_data['price']  = None\n",
    "s_dk_data['pct_change']  = None\n",
    "s_dk_data['MV']  = None\n",
    "s_dk_data['PE']  = None\n",
    "s_dk_data['MA250']  = None\n",
    "s_dk_data['KDJ']  = None\n",
    "s_dk_data['QX']  = None\n",
    "s_dk_data['work']  = None\n",
    "s_dk_data['short_name']  = None\n",
    "s_dk_data['industry']  = None\n",
    "sht.range('A1').value = s_dk_data.query(\"code in @_stock_list\").set_index(\"thscode\")[cols]\n",
    "\n",
    "sht.range(\"B2\").value = '=RTD(\"tdf.quote\",\"\",A2,\"changeRatio\")' \n",
    "sht.range(\"E2\").value = '=RTD(\"tdf.quote\",\"\",A2,\"new\")' \n",
    "sht.range(\"F2\").value = '=(E2/D2-1)*100'\n",
    "sht.range(\"G2\").value = '=(E2/C2-1)*100'\n",
    "sht.range(\"H2\").value = '=(E2/T2-1)*100'\n",
    "xw.Range('A1:W1').color = (230, 0, 0)  # or '#ffffff'\n",
    "xw.Range('A1:W1').font.bold = True\n",
    "xw.Range('A1:W1').row_height = 40\n",
    "xw.Range('A1:W1').column_width = 7\n",
    "xw.Range('A1:W1').api.WrapText = True\n",
    "sht.range('B:D').number_format = '0.00'\n",
    "sht.range('Q:V').number_format = '0'\n",
    "sht.range('Q:V').number_format = '0'\n",
    "sht.range('B:B').api.Font.Bold = True\n",
    "sht.range('S:T').api.Font.Bold = True\n",
    "sht.range('X:X').api.Font.Bold = True\n",
    "xw.Range('B:B').color = (0, 250, 250) \n",
    "xw.Range('I:J').color = (235, 80, 90) \n",
    "sht.range('I:J').api.Font.Bold = True\n",
    "xw.Range('A1:W1').color = (230, 0, 0)  # or '#ffffff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kcsw_list = ['688271.SH','688235.SH','688617.SH','688578.SH','688506.SH','688266.SH','688114.SH','688180.SH','688050.SH','688278.SH','688166.SH',\n",
    "# '688363.SH','688301.SH','688076.SH','688289.SH','688029.SH','688331.SH','688016.SH','688382.SH','688139.SH','688192.SH','688739.SH','688575.SH',\n",
    "# '688520.SH','688321.SH','688131.SH','688091.SH','688062.SH','688366.SH','688198.SH','688639.SH','688443.SH','688212.SH','688389.SH','688336.SH',\n",
    "# '688658.SH','688298.SH','688105.SH','688513.SH','688253.SH','688276.SH','688351.SH','688185.SH','688315.SH','688177.SH','688626.SH','688505.SH','688526.SH','688197.SH','688161.SH']\n",
    "# s_dk_data = s_dk_data.query(\"thscode in @kcsw_list\")\n",
    "# sht= wb.sheets.add(\"科创生物\")\n",
    "# cols = ['pct_change','L_value', 'R_value','price','R_bias','L_bias','MA250_bias','short_name','industry','acitve1', 'acitve2', 'exceed1', 'exceed2',\n",
    "#        'exceed3', 'switch1', 'switch2', 'switch3','PE','MV','MA250', 'KDJ','QX','work',\n",
    "#        ]\n",
    "# s_dk_data['R_bias']  = None\n",
    "# s_dk_data['L_bias']  = None  \n",
    "# s_dk_data['MA250_bias']  = None\n",
    "# s_dk_data['price']  = None\n",
    "# s_dk_data['pct_change']  = None\n",
    "# s_dk_data['MV']  = None\n",
    "# s_dk_data['PE']  = None\n",
    "# s_dk_data['MA250']  = None\n",
    "# s_dk_data['KDJ']  = None\n",
    "# s_dk_data['QX']  = None\n",
    "# s_dk_data['work']  = None\n",
    "# s_dk_data['short_name']  = None\n",
    "# s_dk_data['industry']  = None\n",
    "# sht.range('A1').value = s_dk_data.set_index(\"thscode\")[cols]\n",
    "\n",
    "# sht.range(\"B2\").value = '=RTD(\"tdf.quote\",\"\",A2,\"changeRatio\")' \n",
    "# sht.range(\"E2\").value = '=RTD(\"tdf.quote\",\"\",A2,\"new\")' \n",
    "# sht.range(\"F2\").value = '=(E2/D2-1)*100'\n",
    "# sht.range(\"G2\").value = '=(E2/C2-1)*100'\n",
    "# sht.range(\"H2\").value = '=(E2/T2-1)*100'\n",
    "# xw.Range('A1:W1').color = (230, 0, 0)  # or '#ffffff'\n",
    "# xw.Range('A1:W1').font.bold = True\n",
    "# xw.Range('A1:W1').row_height = 40\n",
    "# xw.Range('A1:W1').column_width = 7\n",
    "# xw.Range('A1:W1').api.WrapText = True\n",
    "# sht.range('B:D').number_format = '0.00'\n",
    "# sht.range('Q:V').number_format = '0'\n",
    "# sht.range('Q:V').number_format = '0'\n",
    "# sht.range('B:B').api.Font.Bold = True\n",
    "# sht.range('S:T').api.Font.Bold = True\n",
    "# sht.range('X:X').api.Font.Bold = True\n",
    "# xw.Range('B:B').color = (0, 250, 250) \n",
    "# xw.Range('I:J').color = (235, 80, 90) \n",
    "# sht.range('I:J').api.Font.Bold = True\n",
    "# xw.Range('A1:W1').color = (230, 0, 0)  # or '#ffffff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = str(max_date)[:10]\n",
    "s_dk_data = dk_data[ (dk_data['date']==d) & (dk_data['code'].isin(_etf_list)) ]\n",
    "s_dk_data['thscode'] = s_dk_data['code'].apply(lambda x : x+\".SZ\" if x[0] in [\"0\",\"1\",\"3\"] else str(x)+\".SH\")\n",
    "symbols = list(s_dk_data['thscode'])\n",
    "data = THS_BD(symbols,'ths_fund_official_short_name_fund;ths_zsz_fund',';%s'%d).data.set_index(\"thscode\")\n",
    "name_dict = data['ths_fund_official_short_name_fund'].to_dict()\n",
    "mv_dict = data['ths_zsz_fund'].to_dict()\n",
    "s_dk_data['short_name'] = s_dk_data['thscode'].apply(lambda x : name_dict[x] if x in name_dict.keys() else 0)\n",
    "s_dk_data['MV'] = s_dk_data['thscode'].apply(lambda x : mv_dict[x] if x in name_dict.keys() else 0)/1e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sht= wb.sheets.add(\"ETF\")\n",
    "cols = ['pct_change','L_value', 'R_value','price','R_bias','L_bias','acitve1', 'acitve2', 'exceed1', 'exceed2',\n",
    "       'exceed3', 'switch1', 'switch2', 'switch3','short_name','MV']\n",
    "s_dk_data['R_bias']  = None\n",
    "s_dk_data['L_bias']  = None  \n",
    "s_dk_data['price']  = None\n",
    "s_dk_data['pct_change']  = None\n",
    "sht.range('A1').value = s_dk_data.query(\"code in @_etf_list\").set_index(\"thscode\")[cols]\n",
    "\n",
    "sht.range(\"B2\").value = '=RTD(\"tdf.quote\",\"\",A2,\"changeRatio\")' \n",
    "sht.range(\"E2\").value = '=RTD(\"tdf.quote\",\"\",A2,\"new\")' \n",
    "sht.range(\"F2\").value = '=(E2/D2-1)*100'\n",
    "sht.range(\"G2\").value = '=(E2/C2-1)*100'\n",
    "sht.range(\"H2\").value = '=(E2/S2-1)*100'\n",
    "xw.Range('A1:W1').color = (230, 0, 0)  # or '#ffffff'\n",
    "xw.Range('A1:W1').font.bold = True\n",
    "xw.Range('A1:W1').row_height = 40\n",
    "xw.Range('A1:W1').column_width = 7\n",
    "xw.Range('A1:W1').api.WrapText = True\n",
    "sht.range('B:H').number_format = '0.00'\n",
    "sht.range('Q:T').number_format = '0.00'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# migrated: use wequant.wefetch.fetch_dk_data instead of local QA_fetch_dk_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = str(max_date)[:10]\n",
    "s_dk_data = fetch_dk_data(list(hkcode_list['code']), d, d, format='pd')\n",
    "assert s_dk_data is not None and len(s_dk_data) > 0\n",
    "symbols = list(s_dk_data['code'])\n",
    "symbols = [i[1:] + '.HK'for i in symbols]\n",
    "s_dk_data['thscode'] = s_dk_data['code'].apply(lambda x : x[1:] + '.HK')\n",
    "data = THS_BD(symbols,'stock_short_name;market_value;pe_multiple_markets',';2025-04-14,OC;2025-04-14,2012').data.set_index(\"thscode\")\n",
    "name_dict = data['stock_short_name'].to_dict()\n",
    "mv_dict = data['market_value'].to_dict()\n",
    "pe_dict = data['pe_multiple_markets'].to_dict()\n",
    "s_dk_data['short_name'] = s_dk_data['thscode'].apply(lambda x : name_dict[x] if x in name_dict.keys() else 0)\n",
    "s_dk_data['MV'] = s_dk_data['thscode'].apply(lambda x : mv_dict[x] if x in name_dict.keys() else 0)/1e8\n",
    "s_dk_data['PE'] = s_dk_data['thscode'].apply(lambda x : pe_dict[x] if x in name_dict.keys() else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sht= wb.sheets.add(\"港股\")\n",
    "cols = ['pct_change','L_value', 'R_value','price','R_bias','L_bias','short_name','MV','PE']\n",
    "s_dk_data['R_bias']  = None\n",
    "s_dk_data['L_bias']  = None  \n",
    "s_dk_data['price']  = None\n",
    "s_dk_data['pct_change']  = None\n",
    "sht.range('A1').value = s_dk_data.set_index(\"thscode\")[cols]\n",
    "\n",
    "sht.range(\"B2\").value = '=RTD(\"tdf.quote\",\"\",A2,\"changeRatio\")' \n",
    "sht.range(\"E2\").value = '=RTD(\"tdf.quote\",\"\",A2,\"new\")' \n",
    "sht.range(\"F2\").value = '=(E2/D2-1)*100'\n",
    "sht.range(\"G2\").value = '=(E2/C2-1)*100'\n",
    "xw.Range('A1:W1').color = (230, 0, 0)  # or '#ffffff'\n",
    "xw.Range('A1:W1').font.bold = True\n",
    "xw.Range('A1:W1').row_height = 40\n",
    "xw.Range('A1:W1').column_width = 7\n",
    "xw.Range('A1:W1').api.WrapText = True\n",
    "sht.range('B:H').number_format = '0.00'\n",
    "sht.range('Q:T').number_format = '0.00'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb.save(\"D:/%s 复盘.xlsx\"%d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in list(dk_data['code'].unique()):\n",
    "    fig = plot(code,dk_data,hq_data)\n",
    "    fig.write_html(r\"D:\\Python Project\\SMCTrading\\SMC/%s.html\"%code,full_html=True)\n",
    "    upload_tecent_png(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_dk_data = dk_data.drop_duplicates(\"code\",keep='last')\n",
    "s_dk_data['close'] = s_dk_data['code'].apply(lambda x : hk_close_dict[x])\n",
    "s_dk_data['name'] = s_dk_data['code'].apply(lambda x : hkcode_list.loc[x]['name'])\n",
    "s_dk_data['page'] = s_dk_data['code'].apply(lambda x : \"https://qa-1303217025.cos.ap-guangzhou.myqcloud.com/SMC/%s.html\"%x )\n",
    "def make_clickable(url):\n",
    "    return f'<a href=\"{url}\" target=\"_blank\">{url}</a>'\n",
    "s_dk_data['page'] = s_dk_data['page'].apply(make_clickable)\n",
    "s_dk_data['R_bias'] = (s_dk_data['close'] - s_dk_data['R_value'])/ s_dk_data['R_value']\n",
    "s_dk_data['L_bias'] = (s_dk_data['close'] - s_dk_data['L_value'])/ s_dk_data['L_value']\n",
    "s_dk_data.to_html(r\"SMC/hk_stock.html\",encoding='GBK',escape=False)\n",
    "bucket_name = 'qa-1303217025'\n",
    "key = \"SMC/hk_stock.html\"\n",
    "local_file =\"SMC/hk_stock.html\"\n",
    "# 执行上传操作\n",
    "response = cos_client.put_object(\n",
    "    Bucket=bucket_name,\n",
    "    Body=open(local_file, 'rb'),\n",
    "    Key=key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed: stray break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwings as xw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = xw.Book(r'C:\\Users\\Administrator\\Downloads\\DK\\奇衡DK星球指数学习材料20250411.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from plotly.subplots import make_subplots\n",
    "def plot(code,dk_data,hq_data):\n",
    "        fig = make_subplots(\n",
    "                rows=2,\n",
    "                shared_xaxes=True,\n",
    "                shared_yaxes=True,\n",
    "                cols=1,\n",
    "                print_grid=False,\n",
    "                vertical_spacing=0,\n",
    "                row_heights = [1,0],\n",
    "                specs=[[{\"secondary_y\": True}],[{\"secondary_y\": True}]])\n",
    "        df = hq_data.query(\"code=='%s'\"%code)\n",
    "        df.index = df['date']\n",
    "        dk_df = dk_data.query(\"code=='%s'\"%code)\n",
    "        def ohlc_trace(df,fig=None,**kwargs):\n",
    "                if fig is None:\n",
    "                        fig = make_subplots()\n",
    "                ohlc =  go.Candlestick(\n",
    "                        x=df.index,\n",
    "                        open=df[\"open\"],\n",
    "                        high=df[\"high\"],\n",
    "                        low=df[\"low\"],\n",
    "                        close=df[\"close\"],\n",
    "                        increasing=dict(line=dict(color=\"red\",width=1),fillcolor='white'),\n",
    "                        decreasing=dict(line=dict(color=\"green\",width=1),fillcolor='green'),\n",
    "                        showlegend=False,\n",
    "                        #hovertext = df[['dates','intrapct','interpct']],\n",
    "                        name=\"candlestick\",   \n",
    "                )\n",
    "                return fig.add_trace(ohlc,**kwargs)\n",
    "        fig = ohlc_trace(df,fig,secondary_y=False,row=1,col=1)\n",
    "        fig.add_traces(\n",
    "                go.Scatter(\n",
    "                        x = dk_df['date'],\n",
    "                        y = dk_df['R_value'],\n",
    "                        line = dict(width=2,color='black'),\n",
    "                        name = 'R_value'\n",
    "                )\n",
    "        )\n",
    "        fig.add_traces(\n",
    "                go.Scatter(\n",
    "                        x = dk_df['date'],\n",
    "                        y = dk_df['L_value'],\n",
    "                        line = dict(width=2,color='black'),\n",
    "                        name = 'L_value'\n",
    "                )\n",
    "        )\n",
    "        fig.add_traces(\n",
    "                go.Scatter(\n",
    "                        x = df['date'],\n",
    "                        y = df['close'].rolling(250).mean(),\n",
    "                        name = 'MA250'\n",
    "                )\n",
    "        )\n",
    "        fig.update_layout(xaxis_rangeslider_visible=False,\n",
    "                        showlegend=False,\n",
    "                        title = code + hkcode_list.loc[code]['name'],\n",
    "                        height = 800 ,width = 1500,\n",
    "                        paper_bgcolor ='lightgrey',\n",
    "                        plot_bgcolor='lightgrey',\n",
    "                        hovermode=\"x unified\")\n",
    "        fig.update_layout(\n",
    "        margin=dict(l=20, r=20, t=20, b=20),\n",
    "        )\n",
    "        return fig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(open,high,low,close,volume,arr,feature_arr,size,logs,col,code,plot_signal=True,plot_enter=True):\n",
    "    date_list = list(np.where(extreme_date[:,0]!=0)[0])\n",
    "    #total_direction = ffill_nb(arr[:,:,SliceIndex.StruDirType])\n",
    "    arr_df  = pd.DataFrame(arr[:,col],columns = SliceIndex._fields)\n",
    "    feature_df = pd.DataFrame(feature_arr[:,col],columns = FeatureIndex._fields).dropna(subset=['Features'])\n",
    "    StruFeatureDict = {i:j for i,j in zip(StruFeatureType._asdict().values(),StruFeatureType._fields)}\n",
    "    feature_df['Features'] = feature_df['Features'].apply(lambda x : StruFeatureDict[x] if ~np.isnan(x) else x)\n",
    "    HLTypeDict = {i:j for i,j in zip(HLTypeType._asdict().values(),HLTypeType._fields)}\n",
    "    arr_df['HLType'] = arr_df['HLType'].apply(lambda x : HLTypeDict[x])\n",
    "    StructerDirDict = {i:j for i,j in zip(StruDirType._asdict().values(),StruDirType._fields)}\n",
    "    arr_df['StruDirType'] = arr_df['StruDirType'].apply(lambda x : StructerDirDict[x] if ~np.isnan(x) else x)\n",
    "    StruReverseDict = {i:j for i,j in zip(StruReverseType._asdict().values(),StruReverseType._fields)}\n",
    "    arr_df['StruReverseType'] = arr_df['StruReverseType'].apply(lambda x : StruReverseDict[x] if ~np.isnan(x) else x)\n",
    "    StruMitigationDict = {i:j for i,j in zip(StruMitigationType._asdict().values(),StruMitigationType._fields)}\n",
    "    arr_df['StruMitigationType'] = arr_df['StruMitigationType'].apply(lambda x : StruMitigationDict[x] if ~np.isnan(x) else x)\n",
    "    filtter_df = arr_df.query(\"IsVaild!=0 and ExtremeDate>0\")\n",
    "    if plot_signal or plot_enter:\n",
    "        signal_df = pd.DataFrame(logs[:,col])\n",
    "        size_df = pd.DataFrame(size[:,col])\n",
    "\n",
    "    dates = list(open_price.index)\n",
    "    fig = make_subplots(\n",
    "            rows=2,\n",
    "            shared_xaxes=True,\n",
    "            shared_yaxes=True,\n",
    "            cols=1,\n",
    "            print_grid=False,\n",
    "            vertical_spacing=0,\n",
    "            row_heights = [1,0],\n",
    "            specs=[[{\"secondary_y\": True}],[{\"secondary_y\": True}]])\n",
    "    # self_dir = pd.DataFrame(pd.DataFrame(total_direction[:,col] - np.nanmax(total_direction[:,col]*0.9))[0]).transpose()\n",
    "    # self_dir.index = [\"\"]\n",
    "    # fig = self_dir.vbt.heatmap(fig = fig,\n",
    "    #                             trace_kwargs=dict(colorscale='Greys',zmid=0),\n",
    "    #                             #heatmap_kwargs = dict(showscale=True),\n",
    "    #                             )\n",
    "    df = pd.DataFrame([open.iloc[:,col],high.iloc[:,col],low.iloc[:,col],close.iloc[:,col],volume.iloc[:,col]]).T\n",
    "    df.index=open_price.index\n",
    "    df.columns = ['open','high','low','close','volume']\n",
    "    df['dates'] = df.index\n",
    "    df.index = range(len(df))\n",
    "    df['intrapct'] = round(df['close']/df['open'] - 1,3)*100\n",
    "    df['interpct'] = round(df['close']/df['close'].shift(1) - 1,3)*100\n",
    "    df['intrapct'] = df['intrapct'].apply(lambda x : \"<br> intrapct:\" + str(round(x,3)))\n",
    "    df['interpct'] = df['interpct'].apply(lambda x : \"<br> interpct:\" + str(round(x,3)))\n",
    "\n",
    "    for i,_df in feature_df.query(\"Features=='HLV'\").drop_duplicates(\"EndDate\").iterrows():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x = [_df['StartDate'],_df['EndDate'],_df['EndDate'],_df['StartDate']],\n",
    "            y = [_df['StartPrice'],_df['StartPrice'],_df['EndPrice'],_df['EndPrice']],\n",
    "            fill='tonext',\n",
    "            mode='lines', \n",
    "            name = 'HFT',\n",
    "            opacity=0.1,\n",
    "            fillcolor = 'rgba(0, 0, 255, 0.5)',\n",
    "            line = dict(width=0.5,)\n",
    "        ),\n",
    "        secondary_y = False\n",
    "        )\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x = [_df['StartDate'],_df['StartMarkDate']],\n",
    "            y = [min([_df['StartPrice'],_df['StartPrice']])]*2,\n",
    "            line=dict(dash='dot',color='rgba(0, 0, 255, 0.5)',width=1),\n",
    "        ),\n",
    "        secondary_y = False\n",
    "        )\n",
    "\n",
    "    for i,_df in feature_df.query(\"Features=='LLV'\").drop_duplicates(\"EndDate\").iterrows():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x = [_df['StartDate'],_df['EndDate'],_df['EndDate'],_df['StartDate']],\n",
    "            y = [_df['StartPrice'],_df['StartPrice'],_df['EndPrice'],_df['EndPrice']],\n",
    "            fill='tonext',\n",
    "            mode='lines', \n",
    "            name = 'LFT',\n",
    "            fillcolor = 'rgba(255, 0, 0, 0.5)',\n",
    "            line = dict(width=0.5,)\n",
    "        ),\n",
    "        secondary_y = False\n",
    "        )\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x = [_df['StartDate'],_df['StartMarkDate']],\n",
    "            y = [min([_df['StartPrice'],_df['StartPrice']])]*2,\n",
    "            line=dict(dash='dot',color='rgba(255, 0, 0, 0.5)',width=1),\n",
    "        ),\n",
    "        secondary_y = False\n",
    "        )\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "            x = filtter_df.query(\"PointType==1\")['ExtremeDate'],\n",
    "            y = filtter_df.query(\"PointType==1\")['ExtremePrice'],\n",
    "            mode = 'markers+text',\n",
    "            text = filtter_df.query(\"PointType==1\")['HLType'],\n",
    "            marker = dict(color='blue',size=5),\n",
    "            textfont = dict(size =10,color='blue'),\n",
    "            ),\n",
    "            secondary_y = True)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "            x = filtter_df.query(\"PointType==1\")['MarkDate'],\n",
    "            y = filtter_df.query(\"PointType==1\")['ExtremePrice'],\n",
    "            mode = 'markers',\n",
    "            marker = dict(color='blue',symbol='triangle-left',size=5),\n",
    "            ),\n",
    "            secondary_y = True)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "            x = filtter_df.query(\"PointType==-1\")['ExtremeDate'],\n",
    "            y = filtter_df.query(\"PointType==-1\")['ExtremePrice'],\n",
    "            mode = 'markers+text',\n",
    "            text = filtter_df.query(\"PointType==-1\")['HLType'],\n",
    "            marker = dict(color='orange',size=7),\n",
    "            textfont = dict(size =10,color='blue'),\n",
    "            ),\n",
    "            secondary_y = True)\n",
    "\n",
    "    for i,_df in feature_df.query(\"Features=='BOS'\").drop_duplicates(\"EndDate\").iterrows():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x = [_df['StartDate'],_df['EndDate']],\n",
    "            y = [_df['StartPrice'],_df['EndPrice']],\n",
    "            line=dict(dash='solid',color='blue',width=1.5),\n",
    "        ),\n",
    "        secondary_y = True\n",
    "        )\n",
    "\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "            x = filtter_df.query(\"PointType==-1\")['MarkDate'],\n",
    "            y = filtter_df.query(\"PointType==-1\")['ExtremePrice'],\n",
    "            mode = 'markers',\n",
    "            marker = dict(color='orange',symbol='triangle-left',size=5)\n",
    "            ),\n",
    "            secondary_y = True)\n",
    "\n",
    "    for i,_df in feature_df.query(\"Features=='BSL'\").drop_duplicates(\"EndDate\").iterrows():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x = [_df['StartDate'],_df['EndDate']],\n",
    "            y = [min([_df['StartPrice'],_df['EndPrice']])]*2,\n",
    "            line=dict(dash='dot',color='cyan',width=1),\n",
    "        ),\n",
    "        secondary_y = True\n",
    "        )\n",
    "\n",
    "    for i,_df in feature_df.query(\"Features=='SSL'\").drop_duplicates(\"EndDate\").iterrows():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x = [_df['StartDate'],_df['EndDate']],\n",
    "            y = [max([_df['StartPrice'],_df['EndPrice']])]*2,\n",
    "            line=dict(dash='dot',color='#f0fcff',width=1),\n",
    "        ),\n",
    "        secondary_y = True\n",
    "        )\n",
    "\n",
    "    for i,_df in feature_df.query(\"Features=='UpBOS'\").drop_duplicates(\"EndDate\").iterrows():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x = [_df['StartDate'],_df['EndDate']],\n",
    "            y = [_df['StartPrice'],_df['EndPrice']],\n",
    "            line=dict(dash='solid',color='blue',width=1.5),\n",
    "        ),\n",
    "        secondary_y = True\n",
    "        )\n",
    "    for i,_df in feature_df.query(\"Features=='UpOB'\").drop_duplicates(\"EndMarkDate\").iterrows():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x = [_df['StartDate'],_df['EndDate'],_df['EndDate'],_df['StartDate']],\n",
    "            y = [_df['StartPrice'],_df['StartPrice'],_df['EndPrice'],_df['EndPrice']],\n",
    "            fill='tonext',\n",
    "            mode='lines', \n",
    "            name = 'OB',\n",
    "            hoverinfo='none',\n",
    "            fillcolor = 'rgba(255, 0, 255, 0.3)',\n",
    "            line = dict(width=0.5,color='rgba(255, 0, 255, 0.3)')\n",
    "        ),\n",
    "        secondary_y = False\n",
    "        )\n",
    "\n",
    "    for i,_df in feature_df.query(\"Features=='FakeBOS'\").drop_duplicates(\"EndDate\").iterrows():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x = [_df['StartDate'],_df['EndDate']],\n",
    "            y = [_df['StartPrice'],_df['EndPrice']],\n",
    "            line=dict(dash='dot',color='blue',width=1.5),\n",
    "        ),\n",
    "        secondary_y = True\n",
    "        )\n",
    "    for i,_df in feature_df.query(\"Features=='FakeOB'\").drop_duplicates(\"EndMarkDate\").iterrows():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x = [_df['StartDate'],_df['EndDate'],_df['EndDate'],_df['StartDate']],\n",
    "            y = [_df['StartPrice'],_df['StartPrice'],_df['EndPrice'],_df['EndPrice']],\n",
    "            fill='tonext',\n",
    "            mode='lines', \n",
    "            name = 'OB',\n",
    "            hoverinfo='none',\n",
    "            fillcolor = 'rgba(255, 0, 255, 0.3)',\n",
    "            line = dict(width=0.5,color='rgba(255, 0, 255, 0.3)',dash='dash')\n",
    "        ),\n",
    "        secondary_y = False\n",
    "        )\n",
    "\n",
    "    for i,_df in feature_df.query(\"Features=='DownBOS'\").drop_duplicates(\"EndDate\").iterrows():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x = [_df['StartDate'],_df['EndDate']],\n",
    "            y = [_df['StartPrice'],_df['EndPrice']],\n",
    "            line=dict(dash='solid',color='red',width=1.5),\n",
    "        ),\n",
    "        secondary_y = True\n",
    "        )\n",
    "    for i,_df in feature_df.query(\"Features=='DownOB'\").drop_duplicates(\"EndMarkDate\").iterrows():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x = [_df['StartDate'],_df['EndDate'],_df['EndDate'],_df['StartDate']],\n",
    "            y = [_df['StartPrice'],_df['StartPrice'],_df['EndPrice'],_df['EndPrice']],\n",
    "            fill='tonext',\n",
    "            mode='lines', \n",
    "            name = 'OB',\n",
    "            hoverinfo='none',\n",
    "            fillcolor = 'rgba(200, 0, 0, 0.3)',\n",
    "            line = dict(width=0.5,color='rgba(255, 0, 255, 0.3)')\n",
    "        ),\n",
    "        secondary_y = False\n",
    "        )\n",
    "    \n",
    "    for i,_df in feature_df.query(\"Features=='MS'\").drop_duplicates(\"EndMarkDate\").iterrows():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x = [_df['StartDate'],_df['EndDate'],_df['EndDate'],_df['StartDate']],\n",
    "            y = [_df['StartPrice'],_df['StartPrice'],_df['EndPrice'],_df['EndPrice']],\n",
    "            fill='tonext',\n",
    "            mode='lines', \n",
    "            name = 'Box',\n",
    "            hoverinfo='none',\n",
    "            fillcolor = 'rgba(100, 200, 0, 0.1)',\n",
    "            line = dict(width=2,color='rgba(100, 200, 0, 0.5)',dash = 'dot')\n",
    "        ),\n",
    "        secondary_y = True\n",
    "        )\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x =[_df['StartMarkDate']],\n",
    "            y = [_df['EndPrice']],\n",
    "            mode = 'markers+text',\n",
    "            text = ['MS'],\n",
    "            marker = dict(color='orange',size=7),\n",
    "            textfont = dict(size =20,color='blue'),\n",
    "            ),\n",
    "        secondary_y = True)\n",
    "\n",
    "\n",
    "    #signal_df = signal_df[size_df[0]!=0]\n",
    "    if plot_signal or plot_enter:\n",
    "        if plot_signal:\n",
    "            signal_df = signal_df[signal_df[0]!=\"\"]\n",
    "        elif plot_enter:\n",
    "            signal_df = signal_df[size_df[0]!=0]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "            x=signal_df.index,\n",
    "            y=df.loc[signal_df.index,'close'],\n",
    "            mode='markers+text',\n",
    "            text = signal_df,\n",
    "            marker=dict(color='black',symbol=150,size=5),\n",
    "            textfont = dict(size =15),\n",
    "            ),\n",
    "            secondary_y=True\n",
    "        )\n",
    "\n",
    "    def ohlc_trace(df,fig=None,**kwargs):\n",
    "        if fig is None:\n",
    "            fig = make_subplots()\n",
    "        ohlc =  go.Candlestick(\n",
    "            x=df.index,\n",
    "            open=df[\"open\"],\n",
    "            high=df[\"high\"],\n",
    "            low=df[\"low\"],\n",
    "            close=df[\"close\"],\n",
    "            increasing=dict(line=dict(color=\"red\",width=1),fillcolor='white'),\n",
    "            decreasing=dict(line=dict(color=\"green\",width=1),fillcolor='green'),\n",
    "            showlegend=False,\n",
    "            hovertext = df[['dates','intrapct','interpct']],\n",
    "            name=\"candlestick\",   \n",
    "        )\n",
    "        return fig.add_trace(ohlc,**kwargs)\n",
    "    if code in list(dk_data[code]):\n",
    "        s_dk_data = dk_data.query(\"code=='%s'\"%code).iloc[0]\n",
    "        fig.add_traces(\n",
    "            go.Scatter(\n",
    "            x = [df.index[-50],df.index[-1]],\n",
    "            y = [s_dk_data['L']]*2,\n",
    "            )\n",
    "            \n",
    "            )\n",
    "\n",
    "        fig.add_traces(\n",
    "            go.Scatter(\n",
    "            x = [df.index[-50],df.index[-1]],\n",
    "            y = [s_dk_data['R']]*2,\n",
    "            )\n",
    "            \n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "    fig = ohlc_trace(df,fig,secondary_y=True,row=1,col=1)\n",
    "    # fig = volume_trace(df,fig,row=2,col=1)\n",
    "    fig.update_layout(xaxis_rangeslider_visible=False,\n",
    "                    showlegend=False,\n",
    "                    height = 500 ,width = 1500,\n",
    "                    paper_bgcolor ='lightgrey',\n",
    "                    plot_bgcolor='lightgrey',\n",
    "                    hovermode=\"x unified\")\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=20, r=20, t=20, b=20),\n",
    "    )\n",
    "    max_value = df['high'].max()+0.1\n",
    "    min_value = df['low'].min()-0.1\n",
    "    fig['layout']['yaxis1'].update(title='', range=[min_value, max_value], autorange=False)\n",
    "    fig['layout']['yaxis2'].update(title='', range=[min_value, max_value], autorange=False)\n",
    "    return fig,feature_df,df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '【V】奇衡DK星球学习材料20241121.xlsx'\n",
    "query_date = file_name.split(\".\")[0][-8:]\n",
    "webond_send_email(sender='2985390793@qq.com',\n",
    "                    receiver = '19113735@qq.com',\n",
    "                    subject = '%s 关键点'%query_date,\n",
    "                    message = '%s 关键点'%query_date,\n",
    "                    attachment_paths=[r\"%s\\%s\"%(root_path,file_name)],\n",
    "                    attachment_filenames=['%s 关键点.xlsx'%query_date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = r\"C:\\Users\\Administrator\\Downloads\\DK\"\n",
    "file_names = os.listdir(root_path)\n",
    "for file_name in file_names:\n",
    "    print(file_name)\n",
    "    total_dk_data = []\n",
    "    dk_data = pd.read_excel(r\"%s\\%s\"%(root_path,file_name),sheet_name=None)\n",
    "    sheet_names = np.array(list(dk_data.keys()))\n",
    "    sheet_name1 = sheet_names[[True if '共享' in x else False  for x in sheet_names]][0]\n",
    "    sheet_name2 = sheet_names[[True if '主连' in x else False  for x in sheet_names]][0]\n",
    "\n",
    "    dk_data = pd.read_excel(r\"%s\\%s\"%(root_path,file_name),sheet_name=sheet_name1)\n",
    "    dk_data.columns = dk_data.iloc[0]\n",
    "    dk_data=dk_data.iloc[1:]\n",
    "    dk_data['code'] = dk_data['NO.'].apply(lambda x : \"0\"*(6-len(str(x))) +  str(x))\n",
    "    dk_data=dk_data.iloc[:,2:]\n",
    "    dk_columns = ['L_value','R_value','R_switch','L_switch','L_label','R_label','R_bias','L_bias','acitve1','activate2','exceed1','exceed2','exceed3','switch1','switch2','switch3','code']\n",
    "    dk_data.columns = dk_columns\n",
    "    total_dk_data.append(dk_data)\n",
    "\n",
    "    dk_data = pd.read_excel(r\"%s\\%s\"%(root_path,file_name),sheet_name=sheet_name2)\n",
    "    dk_data.columns = dk_data.iloc[0]\n",
    "    dk_data=dk_data.iloc[1:]\n",
    "    dk_data['code']=dk_data.iloc[:,0].apply(lambda x : str(x)[:-2])\n",
    "    dk_data=dk_data.iloc[:,2:]\n",
    "    dk_columns = ['L_value','R_value','R_switch','L_switch','L_label','R_label','R_bias','L_bias','acitve1','activate2','exceed1','exceed2','exceed3','switch1','switch2','switch3','code']\n",
    "    dk_data.columns = dk_columns\n",
    "    total_dk_data.append(dk_data)\n",
    "    total_dk_data = pd.concat(total_dk_data)\n",
    "    total_dk_data['datetime'] = file_name.split(\".\")[0][-8:]\n",
    "    total_dk_data = total_dk_data.dropna()\n",
    "    insert_data_json = [i.to_dict() for _,i in total_dk_data.iterrows()]\n",
    "    save_dk_data(pd.DataFrame(insert_data_json))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = r\"C:\\Users\\Administrator\\Downloads\\DK\"\n",
    "file_names = os.listdir(root_path)\n",
    "for file_name in file_names:\n",
    "    print(file_name)\n",
    "    total_dk_data = []\n",
    "    dk_data = pd.read_excel(r\"%s\\%s\"%(root_path,file_name),sheet_name=None)\n",
    "    sheet_names = np.array(list(dk_data.keys()))\n",
    "    sheet_name1 = sheet_names[[True if '共享' in x else False  for x in sheet_names]][0]\n",
    "    sheet_name2 = sheet_names[[True if '主连' in x else False  for x in sheet_names]][0]\n",
    "\n",
    "    dk_data = pd.read_excel(r\"%s\\%s\"%(root_path,file_name),sheet_name=sheet_name1)\n",
    "    dk_data.columns = dk_data.iloc[0]\n",
    "    dk_data=dk_data.iloc[1:]\n",
    "    dk_data['code'] = dk_data['NO.'].apply(lambda x : \"0\"*(6-len(str(x))) +  str(x))\n",
    "    dk_data=dk_data.iloc[:,2:]\n",
    "    dk_columns = ['L_value','R_value','R_switch','L_switch','L_label','R_label','R_bias','L_bias','acitve1','activate2','exceed1','exceed2','exceed3','switch1','switch2','switch3','code']\n",
    "    dk_data.columns = dk_columns\n",
    "    total_dk_data.append(dk_data)\n",
    "\n",
    "    dk_data = pd.read_excel(r\"%s\\%s\"%(root_path,file_name),sheet_name=sheet_name2)\n",
    "    dk_data.columns = dk_data.iloc[0]\n",
    "    dk_data=dk_data.iloc[1:]\n",
    "    dk_data['code']=dk_data.iloc[:,0].apply(lambda x : str(x)[:-2])\n",
    "    dk_data=dk_data.iloc[:,2:]\n",
    "    dk_columns = ['L_value','R_value','R_switch','L_switch','L_label','R_label','R_bias','L_bias','acitve1','activate2','exceed1','exceed2','exceed3','switch1','switch2','switch3','code']\n",
    "    dk_data.columns = dk_columns\n",
    "    total_dk_data.append(dk_data)\n",
    "    total_dk_data = pd.concat(total_dk_data)\n",
    "    total_dk_data['datetime'] = file_name.split(\".\")[0][-8:]\n",
    "    total_dk_data = total_dk_data.dropna()\n",
    "    insert_data_json = [i.to_dict() for _,i in total_dk_data.iterrows()]\n",
    "    save_dk_data(pd.DataFrame(insert_data_json))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# migrated: use wequant.wefetch.fetch_dk_data instead of local QA_fetch_dk_data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wequant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
